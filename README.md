Face Emotion Detection using Transfer Learning
This project implements a real-time face emotion detection system using transfer learning with the MobileNetV2 model. 
The system identifies and classifies facial expressions into various emotion categories, such as happy, sad, angry, surprised, and neutral. 
By leveraging the pre-trained MobileNetV2 model, the project achieves high accuracy while reducing the need for extensive training data.
Features
Real-time Detection: Utilizes webcam input to capture live video feed and detect emotions in real time.
Transfer Learning with MobileNetV2: Applies the MobileNetV2 model, known for its efficiency and speed, to achieve high accuracy with less computational power.
Multiple Emotion Classes: Supports classification of multiple emotions like happy, sad, angry, surprised, and neutral.
Deployed on Render: Accessible via the cloud, allowing easy usage without local setup.
Technologies Used
Python: Core programming language.
OpenCV: For real-time image processing and webcam input.
TensorFlow/Keras: Used for building and training the deep learning model.
MobileNetV2: A lightweight convolutional neural network model used for feature extraction.
Render: Cloud platform for deployment, providing easy access and scalability.
The application is deployed on Render. You can access it directly via https://face-emotion-detection-tlearning.onrender.com
